---
title: "Open-Ended Multi-Modal Relational Reason for Video Question Answering"
collection: publications
permalink: /publication/VQA
excerpt: 'The paper presents a robotic agent for language-based interactions in video scenes, emphasizing the role of trust and achieving a 2% to 3% performance boost over benchmarks.'
date: 2023-06-23
venue: 'IEEE International Conference on Robot and Human Interactive Communication'
paperurl: 
citation: 
---

In this paper, we introduce a robotic agent specifically designed to analyze external environments and address participants' questions. The primary focus of this agent is to assist individuals using language-based interactions within video-based scenes. Our proposed method integrates video recognition technology and natural language processing models within the robotic agent. We investigate the crucial factors affecting human-robot interactions by examining pertinent issues arising between participants and robot agents. Methodologically, our experimental findings reveal a positive relationship between trust and interaction efficiency. Furthermore, our model demonstrates a 2\% to 3\% performance enhancement in comparison to other benchmark methods.

[Download paper here](http://academicpages.github.io/files/2012.00822.pdf)
